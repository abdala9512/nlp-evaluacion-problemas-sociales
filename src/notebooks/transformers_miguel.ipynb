{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd80d353-7f70-4338-8edd-252cb9b55f67",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "822c00a9-cd4e-473f-89d2-fd745e8eeb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import ( \n",
    "    MultiHeadAttention, \n",
    "    LayerNormalization, \n",
    "    Dropout, \n",
    "    Layer,\n",
    "    Embedding, \n",
    "    Input, \n",
    "    GlobalAveragePooling1D, \n",
    "    Dense,\n",
    "    LSTM\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from nlp_utils import basic_cleaning, process_text\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "06bfef0d-3e31-4e8b-9951-3bcfd1aa1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), \n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018de61b-8244-4002-9e53-203a4efe7de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized_list</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12305</th>\n",
       "      <td>cause</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>bajo desempeno fiscal</td>\n",
       "      <td>[bajo, desempeno, fiscal]</td>\n",
       "      <td>bajo desempeno fiscal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>effect</td>\n",
       "      <td>15215.0</td>\n",
       "      <td>aumento en los indices de trabajo infantil.</td>\n",
       "      <td>[aumento, indices, trabajo, infantil]</td>\n",
       "      <td>aumento indices trabajo infantil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>effect</td>\n",
       "      <td>212098.0</td>\n",
       "      <td>inseguridad e incomodidad para usuarios y func...</td>\n",
       "      <td>[inseguridad, incomodidad, usuarios, funcionar...</td>\n",
       "      <td>inseguridad incomodidad usuarios funcionarios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>effect</td>\n",
       "      <td>5373.0</td>\n",
       "      <td>incremento en los indices de pobreza multidime...</td>\n",
       "      <td>[incremento, indices, pobreza, multidimensiona...</td>\n",
       "      <td>incremento indices pobreza multidimensional mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>cause</td>\n",
       "      <td>127192.0</td>\n",
       "      <td>mal estado de las vias</td>\n",
       "      <td>[mal, vias]</td>\n",
       "      <td>mal vias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8700</th>\n",
       "      <td>cause</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>1. vias en mal estado, intransitables o con re...</td>\n",
       "      <td>[vias, mal, intransitables, restricciones, tra...</td>\n",
       "      <td>vias mal intransitables restricciones transito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7119</th>\n",
       "      <td>effect</td>\n",
       "      <td>5399.0</td>\n",
       "      <td>aumento de tiempos de viaje</td>\n",
       "      <td>[aumento, tiempos, viaje]</td>\n",
       "      <td>aumento tiempos viaje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>cause</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.falta de tiempo y dificil desplazamiento  pa...</td>\n",
       "      <td>[tiempo, dificil, desplazamiento, asistir, ied]</td>\n",
       "      <td>tiempo dificil desplazamiento asistir ied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>cause</td>\n",
       "      <td>4603.0</td>\n",
       "      <td>deterioro de las vias</td>\n",
       "      <td>[deterioro, vias]</td>\n",
       "      <td>deterioro vias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11350</th>\n",
       "      <td>cause</td>\n",
       "      <td>4031.0</td>\n",
       "      <td>recursos insuficientes del presupuesto general...</td>\n",
       "      <td>[recursos, insuficientes, presupuesto, general...</td>\n",
       "      <td>recursos insuficientes presupuesto general mun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13037 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target        id                                               text  \\\n",
       "12305   cause    3340.0                              bajo desempeno fiscal   \n",
       "1982   effect   15215.0        aumento en los indices de trabajo infantil.   \n",
       "2447   effect  212098.0  inseguridad e incomodidad para usuarios y func...   \n",
       "3773   effect    5373.0  incremento en los indices de pobreza multidime...   \n",
       "10441   cause  127192.0                             mal estado de las vias   \n",
       "...       ...       ...                                                ...   \n",
       "8700    cause    4784.0  1. vias en mal estado, intransitables o con re...   \n",
       "7119   effect    5399.0                        aumento de tiempos de viaje   \n",
       "1272    cause      10.0  3.falta de tiempo y dificil desplazamiento  pa...   \n",
       "6937    cause    4603.0                              deterioro de las vias   \n",
       "11350   cause    4031.0  recursos insuficientes del presupuesto general...   \n",
       "\n",
       "                                     text_tokenized_list  \\\n",
       "12305                          [bajo, desempeno, fiscal]   \n",
       "1982               [aumento, indices, trabajo, infantil]   \n",
       "2447   [inseguridad, incomodidad, usuarios, funcionar...   \n",
       "3773   [incremento, indices, pobreza, multidimensiona...   \n",
       "10441                                        [mal, vias]   \n",
       "...                                                  ...   \n",
       "8700   [vias, mal, intransitables, restricciones, tra...   \n",
       "7119                           [aumento, tiempos, viaje]   \n",
       "1272     [tiempo, dificil, desplazamiento, asistir, ied]   \n",
       "6937                                   [deterioro, vias]   \n",
       "11350  [recursos, insuficientes, presupuesto, general...   \n",
       "\n",
       "                                          text_tokenized  \n",
       "12305                              bajo desempeno fiscal  \n",
       "1982                    aumento indices trabajo infantil  \n",
       "2447       inseguridad incomodidad usuarios funcionarios  \n",
       "3773   incremento indices pobreza multidimensional mu...  \n",
       "10441                                           mal vias  \n",
       "...                                                  ...  \n",
       "8700      vias mal intransitables restricciones transito  \n",
       "7119                               aumento tiempos viaje  \n",
       "1272           tiempo dificil desplazamiento asistir ied  \n",
       "6937                                      deterioro vias  \n",
       "11350  recursos insuficientes presupuesto general mun...  \n",
       "\n",
       "[13037 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/ArchivoProblemas.csv\", sep=\";\",header=None,)\n",
    "data.columns = [\"target\", \"id\", \"text\"]\n",
    "data = basic_cleaning(data, text_cols=[\"text\"])\n",
    "data[\"text_tokenized_list\"] = data[\"text\"].apply(lambda x: process_text(x, keep_as_list=True))\n",
    "data[\"text_tokenized\"] = data[\"text\"].apply(lambda x: process_text(x, keep_as_list=False))\n",
    "\n",
    "# Shuffle data\n",
    "data = data.sample(frac = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f751a-7626-4a5f-9dc1-7513a121baf5",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "75922e0b-6f5d-4332-ba52-d93d8ba9799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 7\n",
    "VOCAB_SIZE = len(tf_tokenizer.word_index)\n",
    "EMBED_DIM = 100\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y = label_binarizer.fit_transform(data[\"target\"])\n",
    "tf_tokenizer = Tokenizer()\n",
    "fit_text = [\" \".join(data[\"text_tokenized\"])]\n",
    "tf_tokenizer.fit_on_texts(fit_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ed3743c0-92e1-4ac9-bb35-363f57c411d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index(text):\n",
    "    return [ tf_tokenizer.word_index[word] for word in text.split(\" \")]\n",
    "\n",
    "data[\"index_text\"] = data[\"text_tokenized\"].apply(lambda x: text_to_index(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de5f9b-d23f-421d-8f81-d9dea748bb98",
   "metadata": {},
   "source": [
    "# Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d52bc6cb-fdac-40ed-a22e-dfc8cbe14f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "X = np.array(data[\"index_text\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=MAX_LEN)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=MAX_LEN)\n",
    "\n",
    "inputs = Input(shape=(MAX_LEN,))\n",
    "embedding_layer = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE+1, EMBED_DIM)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(EMBED_DIM, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "47ae62fe-dd43-4270-b385-b29211900f3f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "326/326 [==============================] - 5s 12ms/step - loss: 0.4819 - accuracy: 0.7998 - val_loss: 0.3431 - val_accuracy: 0.8700\n",
      "Epoch 2/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.2830 - accuracy: 0.9038 - val_loss: 0.3384 - val_accuracy: 0.8731\n",
      "Epoch 3/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.2114 - accuracy: 0.9301 - val_loss: 0.3799 - val_accuracy: 0.8788\n",
      "Epoch 4/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.1670 - accuracy: 0.9448 - val_loss: 0.3981 - val_accuracy: 0.8838\n",
      "Epoch 5/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.1393 - accuracy: 0.9545 - val_loss: 0.4399 - val_accuracy: 0.8854\n",
      "Epoch 6/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.1232 - accuracy: 0.9595 - val_loss: 0.4831 - val_accuracy: 0.8762\n",
      "Epoch 7/50\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.1120 - accuracy: 0.9630 - val_loss: 0.5957 - val_accuracy: 0.8819\n",
      "Epoch 8/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.1052 - accuracy: 0.9669 - val_loss: 0.5281 - val_accuracy: 0.8865\n",
      "Epoch 9/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0986 - accuracy: 0.9687 - val_loss: 0.6600 - val_accuracy: 0.8834\n",
      "Epoch 10/50\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 0.0944 - accuracy: 0.9685 - val_loss: 0.5743 - val_accuracy: 0.8838\n",
      "Epoch 11/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0891 - accuracy: 0.9709 - val_loss: 0.6443 - val_accuracy: 0.8900\n",
      "Epoch 12/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0835 - accuracy: 0.9736 - val_loss: 0.6416 - val_accuracy: 0.8857\n",
      "Epoch 13/50\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.0747 - accuracy: 0.9767 - val_loss: 0.6684 - val_accuracy: 0.8738\n",
      "Epoch 14/50\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.0863 - accuracy: 0.9729 - val_loss: 0.6834 - val_accuracy: 0.8781\n",
      "Epoch 15/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0801 - accuracy: 0.9760 - val_loss: 0.7577 - val_accuracy: 0.8750\n",
      "Epoch 16/50\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 0.0683 - accuracy: 0.9777 - val_loss: 0.7518 - val_accuracy: 0.8823\n",
      "Epoch 17/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0714 - accuracy: 0.9775 - val_loss: 0.8010 - val_accuracy: 0.8765\n",
      "Epoch 18/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.7511 - val_accuracy: 0.8808\n",
      "Epoch 19/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0687 - accuracy: 0.9787 - val_loss: 0.7514 - val_accuracy: 0.8769\n",
      "Epoch 20/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0761 - accuracy: 0.9757 - val_loss: 0.7099 - val_accuracy: 0.8838\n",
      "Epoch 21/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0655 - accuracy: 0.9800 - val_loss: 0.8217 - val_accuracy: 0.8823\n",
      "Epoch 22/50\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.8760 - val_accuracy: 0.8854\n",
      "Epoch 23/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0576 - accuracy: 0.9822 - val_loss: 0.9335 - val_accuracy: 0.8792\n",
      "Epoch 24/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0679 - accuracy: 0.9772 - val_loss: 0.7963 - val_accuracy: 0.8846\n",
      "Epoch 25/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0603 - accuracy: 0.9806 - val_loss: 0.7897 - val_accuracy: 0.8819\n",
      "Epoch 26/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.8524 - val_accuracy: 0.8815\n",
      "Epoch 27/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 0.8735 - val_accuracy: 0.8781\n",
      "Epoch 28/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0620 - accuracy: 0.9807 - val_loss: 0.8425 - val_accuracy: 0.8838\n",
      "Epoch 29/50\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.0549 - accuracy: 0.9822 - val_loss: 0.9087 - val_accuracy: 0.8815\n",
      "Epoch 30/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 0.9260 - val_accuracy: 0.8834\n",
      "Epoch 31/50\n",
      "326/326 [==============================] - 3s 11ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.9548 - val_accuracy: 0.8758\n",
      "Epoch 32/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0529 - accuracy: 0.9835 - val_loss: 1.0773 - val_accuracy: 0.8788\n",
      "Epoch 33/50\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.0546 - accuracy: 0.9834 - val_loss: 0.9552 - val_accuracy: 0.8815\n",
      "Epoch 34/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0581 - accuracy: 0.9814 - val_loss: 0.8744 - val_accuracy: 0.8804\n",
      "Epoch 35/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 1.0392 - val_accuracy: 0.8746\n",
      "Epoch 36/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 1.0584 - val_accuracy: 0.8781\n",
      "Epoch 37/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0511 - accuracy: 0.9850 - val_loss: 1.0416 - val_accuracy: 0.8800\n",
      "Epoch 38/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0517 - accuracy: 0.9838 - val_loss: 1.0893 - val_accuracy: 0.8792\n",
      "Epoch 39/50\n",
      "326/326 [==============================] - 5s 14ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.9841 - val_accuracy: 0.8773\n",
      "Epoch 40/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0593 - accuracy: 0.9813 - val_loss: 0.9326 - val_accuracy: 0.8800\n",
      "Epoch 41/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.9528 - val_accuracy: 0.8846\n",
      "Epoch 42/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.9213 - val_accuracy: 0.8796\n",
      "Epoch 43/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0508 - accuracy: 0.9838 - val_loss: 0.9454 - val_accuracy: 0.8834\n",
      "Epoch 44/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 1.1183 - val_accuracy: 0.8861\n",
      "Epoch 45/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0483 - accuracy: 0.9847 - val_loss: 1.0759 - val_accuracy: 0.8823\n",
      "Epoch 46/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 1.1148 - val_accuracy: 0.8815\n",
      "Epoch 47/50\n",
      "326/326 [==============================] - 4s 13ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 0.9207 - val_accuracy: 0.8808\n",
      "Epoch 48/50\n",
      "326/326 [==============================] - 4s 12ms/step - loss: 0.0513 - accuracy: 0.9825 - val_loss: 0.9823 - val_accuracy: 0.8823\n",
      "Epoch 49/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0570 - accuracy: 0.9835 - val_loss: 0.9446 - val_accuracy: 0.8808\n",
      "Epoch 50/50\n",
      "326/326 [==============================] - 4s 11ms/step - loss: 0.0503 - accuracy: 0.9833 - val_loss: 1.0140 - val_accuracy: 0.8785\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=32, epochs=50, \n",
    "                    validation_data=(X_test, y_test)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ee012-0f5f-4de3-8b2d-2088e08a260f",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3352a17e-2e62-4720-9f53-0012820eafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_nn():\n",
    "    NeuralNetwork = Sequential()\n",
    "    NeuralNetwork.add(Input(shape=(MAX_LEN,)))\n",
    "    NeuralNetwork.add(Embedding(input_dim=VOCAB_SIZE+1, output_dim=EMBED_DIM))\n",
    "    NeuralNetwork.add(LSTM(128))\n",
    "    NeuralNetwork.add(Dense(128, activation=\"relu\"))\n",
    "    NeuralNetwork.add(Dropout(0.1))\n",
    "    NeuralNetwork.add(Dense(16, activation=\"relu\"))\n",
    "    NeuralNetwork.add(Dropout(0.1))\n",
    "    NeuralNetwork.add(Dense(3, activation=\"softmax\"))\n",
    "    print('NeuralNetwork architecture: \\n')\n",
    "    print(NeuralNetwork.summary())  \n",
    "    return NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5c360dbc-16e0-466a-8aae-ba60b9b55634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork architecture: \n",
      "\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_93 (Embedding)    (None, 7, 100)            541800    \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 128)               117248    \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677,675\n",
      "Trainable params: 677,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn_model = define_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ec60850e-37aa-4118-a245-152f864d1195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "163/163 [==============================] - 3s 12ms/step - loss: 0.5461 - accuracy: 0.7616 - val_loss: 0.3634 - val_accuracy: 0.8654\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.2908 - accuracy: 0.9043 - val_loss: 0.3435 - val_accuracy: 0.8823\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.2142 - accuracy: 0.9342 - val_loss: 0.3422 - val_accuracy: 0.8827\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.1713 - accuracy: 0.9497 - val_loss: 0.3796 - val_accuracy: 0.8865\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.1471 - accuracy: 0.9590 - val_loss: 0.3970 - val_accuracy: 0.8884\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 2s 9ms/step - loss: 0.1235 - accuracy: 0.9640 - val_loss: 0.4300 - val_accuracy: 0.8800\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 2s 9ms/step - loss: 0.1098 - accuracy: 0.9663 - val_loss: 0.5330 - val_accuracy: 0.8765\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.5332 - val_accuracy: 0.8861\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 0.0918 - accuracy: 0.9730 - val_loss: 0.6151 - val_accuracy: 0.8834\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 0.0795 - accuracy: 0.9761 - val_loss: 0.7302 - val_accuracy: 0.8907\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0830 - accuracy: 0.9747 - val_loss: 0.6360 - val_accuracy: 0.8865\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.0759 - accuracy: 0.9767 - val_loss: 0.6513 - val_accuracy: 0.8857\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0743 - accuracy: 0.9780 - val_loss: 0.6853 - val_accuracy: 0.8827\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0775 - accuracy: 0.9765 - val_loss: 0.6118 - val_accuracy: 0.8857\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: 0.7021 - val_accuracy: 0.8808\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0648 - accuracy: 0.9800 - val_loss: 0.7021 - val_accuracy: 0.8846\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0675 - accuracy: 0.9794 - val_loss: 0.7706 - val_accuracy: 0.8877\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.0685 - accuracy: 0.9807 - val_loss: 0.7641 - val_accuracy: 0.8873\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0625 - accuracy: 0.9812 - val_loss: 0.8138 - val_accuracy: 0.8869\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0611 - accuracy: 0.9825 - val_loss: 0.7098 - val_accuracy: 0.8896\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0626 - accuracy: 0.9825 - val_loss: 0.7623 - val_accuracy: 0.8884\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0593 - accuracy: 0.9827 - val_loss: 0.8100 - val_accuracy: 0.8850\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0559 - accuracy: 0.9837 - val_loss: 0.8563 - val_accuracy: 0.8877\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 0.8757 - val_accuracy: 0.8865\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0553 - accuracy: 0.9836 - val_loss: 0.7763 - val_accuracy: 0.8831\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.8716 - val_accuracy: 0.8831\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0627 - accuracy: 0.9809 - val_loss: 0.7519 - val_accuracy: 0.8781\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 0.8076 - val_accuracy: 0.8834\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0554 - accuracy: 0.9829 - val_loss: 0.8609 - val_accuracy: 0.8884\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.8771 - val_accuracy: 0.8877\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.8489 - val_accuracy: 0.8850\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 0.9271 - val_accuracy: 0.8861\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.9669 - val_accuracy: 0.8884\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.8410 - val_accuracy: 0.8857\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0571 - accuracy: 0.9834 - val_loss: 0.8326 - val_accuracy: 0.8854\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0498 - accuracy: 0.9850 - val_loss: 0.9319 - val_accuracy: 0.8877\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0481 - accuracy: 0.9856 - val_loss: 0.9324 - val_accuracy: 0.8857\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0469 - accuracy: 0.9857 - val_loss: 1.0861 - val_accuracy: 0.8865\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0471 - accuracy: 0.9862 - val_loss: 1.0351 - val_accuracy: 0.8877\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 1.0178 - val_accuracy: 0.8861\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 2s 13ms/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 1.0661 - val_accuracy: 0.8892\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 2s 13ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 1.1153 - val_accuracy: 0.8888\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 1.1307 - val_accuracy: 0.8919\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0457 - accuracy: 0.9865 - val_loss: 1.2971 - val_accuracy: 0.8850\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 2s 13ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 1.1059 - val_accuracy: 0.8877\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 1.2292 - val_accuracy: 0.8857\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.0617 - accuracy: 0.9820 - val_loss: 0.8176 - val_accuracy: 0.8873\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.0655 - accuracy: 0.9801 - val_loss: 0.7540 - val_accuracy: 0.8884\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 2s 11ms/step - loss: 0.0527 - accuracy: 0.9845 - val_loss: 0.8814 - val_accuracy: 0.8861\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 2s 10ms/step - loss: 0.0481 - accuracy: 0.9846 - val_loss: 0.9015 - val_accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "nn_model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "history = nn_model.fit(X_train, y_train, \n",
    "                    batch_size=64, epochs=50, \n",
    "                    validation_data=(X_test, y_test)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52ac6d-9fa5-4a0f-89de-df1253aa207f",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0e21c264-4f0d-419f-b007-c37931ca10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_prediction(\n",
    "    text: str, model, \n",
    "    prediction_threshold: float = 0.35\n",
    "    ) -> str:\n",
    "    \"\"\"Make prediction for Selected neural network\n",
    "    \"\"\"\n",
    "    tokenized = \" \".join([\n",
    "        word for word in process_text(text.lower()).split(\" \")\n",
    "        if word in list(tf_tokenizer.word_index.keys())\n",
    "    ])\n",
    "    \n",
    "    vector_ = tf.keras.preprocessing.sequence.pad_sequences( \n",
    "        np.array(text_to_index(tokenized)).reshape(1,-1),  maxlen=MAX_LEN\n",
    "    )\n",
    "    \n",
    "    probabilities = np.array(model.predict(vector_))\n",
    "    predictions = {\n",
    "        label_binarizer.classes_[i]: probabilities[0][i]\n",
    "        for i in range(3)\n",
    "    }\n",
    "    \n",
    "    if any([prob > prediction_threshold for prob in list(predictions.values())]):\n",
    "        return max(predictions, key=predictions.get)\n",
    "    return \"Predicciones no superan el umbral para seleccionar almenos una categoria\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "8b7b7206-ff62-4d71-b156-cb485b462f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cause'"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(\"recursos insuficientes del presupuest \", model=nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2301b38-59b5-4c76-b45f-d9c7f7e0dd48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
